{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f55c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor, early_stopping\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21aadb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_adjusted(y_true: np.ndarray, y_pred: np.ndarray,\n",
    "                X_test: np.ndarray) -> float:\n",
    "    \"\"\"Коэффициент детерминации (множественная регрессия)\"\"\"\n",
    "    N_objects = len(y_true)\n",
    "    N_features = X_test.shape[1]\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return 1 - (1 - r2) * (N_objects - 1) / (N_objects - N_features - 1)\n",
    "\n",
    "\n",
    "def wape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Weighted Absolute Percent Error\"\"\"\n",
    "    return np.sum(np.abs(y_pred - y_true)) / np.sum(y_true) * 100\n",
    "\n",
    "\n",
    "def get_metrics_regression(y_test: np.ndarray,\n",
    "                           y_pred: np.ndarray,\n",
    "                           X_test: np.ndarray,\n",
    "                           name: str = None,\n",
    "                           delta: float = 1.345):\n",
    "    \"\"\"Генерация таблицы с метриками для задачи регрессии\"\"\"\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "    df_metrics['model'] = [name]\n",
    "\n",
    "    df_metrics['MAE'] = mean_absolute_error(y_test, y_pred)\n",
    "    df_metrics['RMSE'] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    df_metrics['R2 adjusted'] = r2_adjusted(y_test, y_pred, X_test)\n",
    "    df_metrics['WAPE_%'] = wape(y_test, y_pred)\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b34cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm_cv(**params: dict) -> tuple[list, float]:\n",
    "    \"\"\"\n",
    "    Функция, обучающая модель LGBMRegressor на кросс-валидации\n",
    "    с 6 фолдами(разбиение на фолды по пациентам, в последнем фолде\n",
    "    объединены 1 и 6 пациенты) с заданными параметрами\n",
    "    Выводит средние по фолдам метрики на тренировочных и \n",
    "    валидационных данных и дельту между ними\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Словарь с параметрами модели LGBMRegressor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Массив с предсказаниями на holdout для каждого фолда\n",
    "    и среднюю метрику по фолдам на трейне для подсчета дельты между \n",
    "    метриками на трейне и на отложенной выборке\n",
    "    \"\"\"\n",
    "    mae_oof = np.empty(6)\n",
    "    mae_train_oof = np.empty(6)\n",
    "    predicts_test = []\n",
    "    # первые пять фолдов\n",
    "    for idx, patient in enumerate(patients):\n",
    "        X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'],\n",
    "                                                       axis=1)\n",
    "        y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "        y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(X_train_,\n",
    "                  y_train_,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric=\"mae\",\n",
    "                  callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_train_pred = model.predict(X_train_)\n",
    "\n",
    "        mae_oof[idx] = mean_absolute_error(y_val, y_val_pred)\n",
    "        mae_train_oof[idx] = mean_absolute_error(y_train_, y_train_pred)\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        predicts_test.append(y_test_pred)\n",
    "\n",
    "        print(\n",
    "            f\"MAE fold {idx + 1} = {mean_absolute_error(y_val, y_val_pred):.3f}\"\n",
    "        )\n",
    "        print('---')\n",
    "\n",
    "    # последний фолд(1 + 6 пациенты)\n",
    "    X_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))].drop(['p_num', 'target'],\n",
    "                                                         axis=1)\n",
    "    X_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))]['target']\n",
    "    y_val = train.loc[(train.p_num == 'p06') |\n",
    "                      (train.p_num == 'p01')]['target']\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric=\"mae\",\n",
    "              callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_train_pred = model.predict(X_train_)\n",
    "\n",
    "    mae_oof[idx + 1] = mean_absolute_error(y_val, y_val_pred)\n",
    "    mae_train_oof[idx + 1] = mean_absolute_error(y_train_, y_train_pred)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    predicts_test.append(y_test_pred)\n",
    "\n",
    "    print(f\"MAE fold {idx + 2} = {mean_absolute_error(y_val, y_val_pred):.3f}\")\n",
    "    print('---')\n",
    "\n",
    "    avg_mae_val = np.mean(mae_oof)\n",
    "    avg_mae_train = np.mean(mae_train_oof)\n",
    "    print(f\"Mean MAE val = {avg_mae_val}\")\n",
    "    print(f\"Mean MAE train = {avg_mae_train}\")\n",
    "    print(\n",
    "        f\"Delta between train and val = {(abs(avg_mae_train - avg_mae_val) / avg_mae_train * 100):.1f} %\"\n",
    "    )\n",
    "\n",
    "    return predicts_test, avg_mae_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a3ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost_cv(**params: dict) -> tuple[list, float]:\n",
    "    \"\"\"\n",
    "    Функция, обучающая модель CatBoostRegressor на кросс-валидации\n",
    "    с 6 фолдами(разбиение на фолды по пациентам, в последнем фолде\n",
    "    объединены 1 и 6 пациенты) с заданными параметрами\n",
    "    Выводит средние по фолдам метрики на тренировочных и \n",
    "    валидационных данных и дельту между ними\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    Словарь с параметрами модели LGBMRegressor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Массив с предсказаниями на holdout для каждого фолда\n",
    "    и среднюю метрику по фолдам на трейне для подсчета дельты между \n",
    "    метриками на трейне и на отложенной выборке\n",
    "    \"\"\"\n",
    "    mae_oof = np.empty(6)\n",
    "    mae_train_oof = np.empty(6)\n",
    "    predicts_test = []\n",
    "    # первые пять фолдов\n",
    "    for idx, patient in enumerate(patients):\n",
    "        X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        X_val = train.loc[train.p_num == patient].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "        y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "\n",
    "        eval_set = [(X_val, y_val)]\n",
    "\n",
    "        model.fit(X_train_,\n",
    "                  y_train_,\n",
    "                  eval_set=eval_set,\n",
    "                  verbose=False,\n",
    "                  early_stopping_rounds=100)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        y_train_pred = model.predict(X_train_)\n",
    "\n",
    "        mae_oof[idx] = mean_absolute_error(y_val, y_val_pred)\n",
    "        mae_train_oof[idx] = mean_absolute_error(y_train_, y_train_pred)\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        predicts_test.append(y_test_pred)\n",
    "\n",
    "        print(\n",
    "            f\"MAE fold {idx + 1} = {mean_absolute_error(y_val, y_val_pred):.3f}\")\n",
    "        print('---')\n",
    "\n",
    "    # последний фолд(1 + 6 пациенты)\n",
    "    X_train_ = train.loc[~((train.p_num == 'p06') | (train.p_num == 'p01'))].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    X_val = train.loc[(train.p_num == 'p06') | (\n",
    "        train.p_num == 'p01')].drop(['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))]['target']\n",
    "    y_val = train.loc[(train.p_num == 'p06') | (\n",
    "        train.p_num == 'p01')]['target']\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "\n",
    "    eval_set = [(X_val, y_val)]\n",
    "\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=eval_set,\n",
    "              verbose=False,\n",
    "              early_stopping_rounds=100)\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_train_pred = model.predict(X_train_)\n",
    "\n",
    "    mae_oof[idx + 1] = mean_absolute_error(y_val, y_val_pred)\n",
    "    mae_train_oof[idx + 1] = mean_absolute_error(y_train_, y_train_pred)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    predicts_test.append(y_test_pred)\n",
    "\n",
    "    print(f\"MAE fold {idx + 2} = {mean_absolute_error(y_val, y_val_pred):.3f}\")\n",
    "    print('---')\n",
    "\n",
    "    avg_mae_val = np.mean(mae_oof)\n",
    "    avg_mae_train = np.mean(mae_train_oof)\n",
    "    print(f\"Mean MAE val = {avg_mae_val}\")\n",
    "    print(f\"Mean MAE train = {avg_mae_train}\")\n",
    "    print(\n",
    "        f\"Delta between train and val = {(abs(avg_mae_train - avg_mae_val) / avg_mae_train * 100):.1f} %\")\n",
    "\n",
    "    return predicts_test, avg_mae_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73cfcce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ae78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test.drop(['p_num', 'target'], axis=1), test['target']\n",
    "X_train, y_train = train.drop(['p_num', 'target'], axis=1), train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef331a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = ['p02', 'p10', 'p12', 'p04', 'p11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92bea530",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(\"metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbd0dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad09d4",
   "metadata": {},
   "source": [
    "# Tuning LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860194b6",
   "metadata": {},
   "source": [
    "## LGBM Tune 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_1_lgb(trial):\n",
    "    lgb_params = {\n",
    "        \"random_state\":\n",
    "        trial.suggest_categorical(\"random_state\", [42]),\n",
    "        \"verbose\":\n",
    "        trial.suggest_categorical(\"verbose\", [-1]),\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [100]),\n",
    "        \"objective\":\n",
    "        trial.suggest_categorical(\"objective\", ['mae']),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_categorical(\"learning_rate\", [0.05621533613556329]),\n",
    "        #          \"objective\":\n",
    "        #         trial.suggest_categorical(\"objective\", ['mae', 'rmse', None]),\n",
    "        #         \"learning_rate\":\n",
    "        #         trial.suggest_float(\"learning_rate\", 0.045, 0.06, log=True),\n",
    "        \"num_leaves\":\n",
    "        trial.suggest_int(\"num_leaves\", 16, 25),\n",
    "        \"max_depth\":\n",
    "        trial.suggest_int(\"max_depth\", 6, 10),\n",
    "        \"max_bin\":\n",
    "        trial.suggest_int(\"max_bin\", 100, 250, step=10),\n",
    "        \"min_child_samples\":\n",
    "        trial.suggest_int(\"min_child_samples\", 100, 1000, step=100),\n",
    "        \"min_split_gain\":\n",
    "        trial.suggest_float(\"min_split_gain\", 0.0, 0.9, step=0.1),\n",
    "        \"subsample\":\n",
    "        trial.suggest_float(\"subsample\", 0.8, 1.0),\n",
    "        \"subsample_freq\":\n",
    "        trial.suggest_int(\"subsample_freq\", 1, 3),\n",
    "        \"colsample_bytree\":\n",
    "        trial.suggest_float(\"colsample_bytree\", 0.8, 1.0),\n",
    "        \"reg_alpha\":\n",
    "        trial.suggest_int(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\":\n",
    "        trial.suggest_int(\"reg_lambda\", 0, 100)\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'mae')\n",
    "\n",
    "    mae_oof = np.empty(6)\n",
    "    for idx, patient in enumerate(patients):\n",
    "        X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'],\n",
    "                                                       axis=1)\n",
    "        y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "        y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        model.fit(X_train_,\n",
    "                  y_train_,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric=\"mae\")\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        mae_oof[idx] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    # последний фолд(1 + 6 пациенты)\n",
    "    X_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))].drop(['p_num', 'target'],\n",
    "                                                         axis=1)\n",
    "    X_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))]['target']\n",
    "    y_val = train.loc[(train.p_num == 'p06') |\n",
    "                      (train.p_num == 'p01')]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgb_params)\n",
    "    model.fit(X_train_, y_train_, eval_set=[(X_val, y_val)], eval_metric=\"mae\")\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    mae_oof[idx + 1] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    return np.mean(mae_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0196734",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_1_lgb = optuna.create_study(direction=\"minimize\", study_name=\"LGB_1\")\n",
    "study_1_lgb.optimize(objective_1_lgb, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dddbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_1_lgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_1_lgb.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "501b9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь и далее сохраняла лучшие параметры Optuna для каждого study в отдельную переменную, так как при перезапуске ячейки\n",
    "# результаты не воспроизводятся\n",
    "lgbm_1_params = {'random_state': 42,\n",
    "                 'verbose': -1,\n",
    "                 'n_estimators': 100,\n",
    "                 'objective': 'mae',\n",
    "                 'learning_rate': 0.05621533613556329,\n",
    "                 'num_leaves': 21,\n",
    "                 'max_depth': 7,\n",
    "                 'max_bin': 230,\n",
    "                 'min_child_samples': 1000,\n",
    "                 'min_split_gain': 0.2,\n",
    "                 'subsample': 0.9479574040260543,\n",
    "                 'subsample_freq': 1,\n",
    "                 'colsample_bytree': 0.9489394374238439,\n",
    "                 'reg_alpha': 1,\n",
    "                 'reg_lambda': 12}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f7434",
   "metadata": {},
   "source": [
    "**Проверяем подобранные параметры на CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3777ce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 1.65099\n",
      "MAE fold 1 = 1.651\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[81]\tvalid_0's l1: 1.18964\n",
      "MAE fold 2 = 1.190\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\tvalid_0's l1: 1.29595\n",
      "MAE fold 3 = 1.296\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 1.49862\n",
      "MAE fold 4 = 1.499\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's l1: 1.75268\n",
      "MAE fold 5 = 1.753\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 1.98058\n",
      "MAE fold 6 = 1.981\n",
      "---\n",
      "Mean MAE val = 1.5614111845742074\n",
      "Mean MAE train = 1.3660528284839402\n",
      "Delta between train and val = 14.3 %\n",
      "CPU times: total: 6min 7s\n",
      "Wall time: 52.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predicts_test, avg_mae_train = train_lgbm_cv(**lgbm_1_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1a5dc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE holdout = 1.629734136399079\n",
      "Delta between train and holdout = 19.3 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_preds = np.mean(np.column_stack(predicts_test), axis=1)\n",
    "mae_holdout = mean_absolute_error(y_test, holdout_preds)\n",
    "print(f\"MAE holdout = {mae_holdout}\")\n",
    "print(\n",
    "    f\"Delta between train and holdout = {(abs(avg_mae_train - mae_holdout) / avg_mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, holdout_preds, X_test, 'lgbm tune 1')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff0a4d",
   "metadata": {},
   "source": [
    "Подбор гиперпараметров способствовал значительному снижению переобучения: разница между метриками на трейне и валидации, а также между метриками на трейне и на отложенной выборке значительно уменьшилась (у baseline LGBM с кросс-валидацией разница между метриками на трейне и валидации была 19.1%, а между метриками на трейне и отложенной выборке - 23.1%). \\\n",
    "Однако переобучение все еще большое, поэтому попробуем несколько раз подобрать гиперпараметры для LGBM на кросс-валидации, чтобы найти лучшую комбинацию гиперпараметров (затем можно провести стэкинг лучших моделей)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e020e",
   "metadata": {},
   "source": [
    "## LGBM Tune 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa8a3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_2_lgb(trial):\n",
    "    lgb_params = {\n",
    "        \"random_state\":\n",
    "        trial.suggest_categorical(\"random_state\", [42]),\n",
    "        \"verbose\":\n",
    "        trial.suggest_categorical(\"verbose\", [-1]),\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [100]),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_categorical(\"learning_rate\", [0.053402226219538856]),\n",
    "        #         \"learning_rate\":\n",
    "        #         trial.suggest_float(\"learning_rate\", 0.05, 0.06, log=True),\n",
    "        #          \"objective\":\n",
    "        #         trial.suggest_categorical(\"objective\", ['mae', 'rmse', None]),\n",
    "        \"num_leaves\":\n",
    "        trial.suggest_int(\"num_leaves\", 16, 30),\n",
    "        \"max_depth\":\n",
    "        trial.suggest_int(\"max_depth\", 6, 12),\n",
    "        \"max_bin\":\n",
    "        trial.suggest_int(\"max_bin\", 100, 250, step=10),\n",
    "        \"min_child_samples\":\n",
    "        trial.suggest_int(\"min_child_samples\", 100, 1000, step=100),\n",
    "        \"min_split_gain\":\n",
    "        trial.suggest_float(\"min_split_gain\", 0.0, 0.9, step=0.1),\n",
    "        \"subsample\":\n",
    "        trial.suggest_float(\"subsample\", 0.8, 1.0),\n",
    "        \"subsample_freq\":\n",
    "        trial.suggest_int(\"subsample_freq\", 1, 3),\n",
    "        \"colsample_bytree\":\n",
    "        trial.suggest_float(\"colsample_bytree\", 0.8, 1.0),\n",
    "        \"reg_alpha\":\n",
    "        trial.suggest_int(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\":\n",
    "        trial.suggest_int(\"reg_lambda\", 0, 100)\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'mae')\n",
    "\n",
    "    mae_oof = np.empty(6)\n",
    "    for idx, patient in enumerate(patients):\n",
    "        X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'],\n",
    "                                                       axis=1)\n",
    "        y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "        y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        model.fit(X_train_,\n",
    "                  y_train_,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric=\"mae\")\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        mae_oof[idx] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    # последний фолд(1 + 6 пациенты)\n",
    "    X_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))].drop(['p_num', 'target'],\n",
    "                                                         axis=1)\n",
    "    X_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))]['target']\n",
    "    y_val = train.loc[(train.p_num == 'p06') |\n",
    "                      (train.p_num == 'p01')]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgb_params)\n",
    "    model.fit(X_train_, y_train_, eval_set=[(X_val, y_val)], eval_metric=\"mae\")\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    mae_oof[idx + 1] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    return np.mean(mae_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_2_lgb = optuna.create_study(direction=\"minimize\", study_name=\"LGB_2\")\n",
    "study_2_lgb.optimize(objective_2_lgb, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_2_lgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_2_lgb.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07b9c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_2_params = {'random_state': 42,\n",
    "                 'verbose': -1,\n",
    "                 'n_estimators': 100,\n",
    "                 'learning_rate': 0.053402226219538856,\n",
    "                 'num_leaves': 19,\n",
    "                 'max_depth': 11,\n",
    "                 'max_bin': 200,\n",
    "                 'min_child_samples': 800,\n",
    "                 'min_split_gain': 0.0,\n",
    "                 'subsample': 0.9388008791697994,\n",
    "                 'subsample_freq': 3,\n",
    "                 'colsample_bytree': 0.9709495705457634,\n",
    "                 'reg_alpha': 30,\n",
    "                 'reg_lambda': 33}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb5f7b",
   "metadata": {},
   "source": [
    "**Проверяем подобранные параметры на CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aad3ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[94]\tvalid_0's l1: 1.63002\tvalid_0's l2: 5.10138\n",
      "MAE fold 1 = 1.630\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 1.29186\tvalid_0's l2: 2.63065\n",
      "MAE fold 2 = 1.292\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[81]\tvalid_0's l1: 1.31681\tvalid_0's l2: 3.19354\n",
      "MAE fold 3 = 1.317\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's l1: 1.543\tvalid_0's l2: 4.1296\n",
      "MAE fold 4 = 1.543\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's l1: 1.70939\tvalid_0's l2: 5.11418\n",
      "MAE fold 5 = 1.709\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's l1: 1.96795\tvalid_0's l2: 6.59215\n",
      "MAE fold 6 = 1.968\n",
      "---\n",
      "Mean MAE val = 1.5765051576618914\n",
      "Mean MAE train = 1.380549725646684\n",
      "Delta between train and val = 14.2 %\n"
     ]
    }
   ],
   "source": [
    "predicts_test, avg_mae_train = train_lgbm_cv(**lgbm_2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ca43bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE holdout = 1.6322344422563935\n",
      "Delta between train and holdout = 18.2 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 2</td>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901\n",
       "0                lgbm tune 2  1.632234  2.165808     0.519434  19.259403"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_preds = np.mean(np.column_stack(predicts_test), axis=1)\n",
    "mae_holdout = mean_absolute_error(y_test, holdout_preds)\n",
    "print(f\"MAE holdout = {mae_holdout}\")\n",
    "print(\n",
    "    f\"Delta between train and holdout = {(abs(avg_mae_train - mae_holdout) / avg_mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, holdout_preds, X_test, 'lgbm tune 2')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb1018",
   "metadata": {},
   "source": [
    "Данная комбинация гиперпараметров привела к еще большему снижению переобучения. При этом метрика на Holdout немного ухудшилась, но незначительно. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf5e6f",
   "metadata": {},
   "source": [
    "## LGBM Tune 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c66edb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_3_lgb(trial):\n",
    "    lgb_params = {\n",
    "        \"random_state\":\n",
    "        trial.suggest_categorical(\"random_state\", [42]),\n",
    "        \"verbose\":\n",
    "        trial.suggest_categorical(\"verbose\", [-1]),\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [500]),\n",
    "        \"objective\":\n",
    "        trial.suggest_categorical(\"objective\", ['mae']),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_categorical(\"learning_rate\", [0.014912792408663157]),\n",
    "        #          \"objective\":\n",
    "        #         trial.suggest_categorical(\"objective\", ['mae', 'rmse', None]),\n",
    "        #         \"learning_rate\":\n",
    "        #         trial.suggest_float(\"learning_rate\", 0.009, 0.025, log=True),\n",
    "        \"num_leaves\":\n",
    "        trial.suggest_int(\"num_leaves\", 16, 25),\n",
    "        \"max_depth\":\n",
    "        trial.suggest_int(\"max_depth\", 6, 10),\n",
    "        \"max_bin\":\n",
    "        trial.suggest_int(\"max_bin\", 100, 250, step=10),\n",
    "        \"min_child_samples\":\n",
    "        trial.suggest_int(\"min_child_samples\", 100, 1000, step=100),\n",
    "        \"min_split_gain\":\n",
    "        trial.suggest_float(\"min_split_gain\", 0.0, 0.9, step=0.1),\n",
    "        \"subsample\":\n",
    "        trial.suggest_float(\"subsample\", 0.8, 1.0),\n",
    "        \"subsample_freq\":\n",
    "        trial.suggest_int(\"subsample_freq\", 1, 3),\n",
    "        \"colsample_bytree\":\n",
    "        trial.suggest_float(\"colsample_bytree\", 0.8, 1.0),\n",
    "        \"reg_alpha\":\n",
    "        trial.suggest_int(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\":\n",
    "        trial.suggest_int(\"reg_lambda\", 0, 100)\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'mae')\n",
    "\n",
    "    mae_oof = np.empty(6)\n",
    "    for idx, patient in enumerate(patients):\n",
    "        X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'],\n",
    "                                                       axis=1)\n",
    "        y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "        y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        model.fit(X_train_,\n",
    "                  y_train_,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric=\"mae\",\n",
    "                  callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        mae_oof[idx] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    # последний фолд(1 + 6 пациенты)\n",
    "    X_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))].drop(['p_num', 'target'],\n",
    "                                                         axis=1)\n",
    "    X_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))]['target']\n",
    "    y_val = train.loc[(train.p_num == 'p06') |\n",
    "                      (train.p_num == 'p01')]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgb_params)\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric=\"mae\",\n",
    "              callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    mae_oof[idx + 1] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    return np.mean(mae_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06afc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_3_lgb = optuna.create_study(direction=\"minimize\", study_name=\"LGB_3\")\n",
    "study_3_lgb.optimize(objective_3_lgb, n_trials=15, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be61efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_3_lgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_3_lgb.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8388c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_3_params = {'random_state': 42,\n",
    "                 'verbose': -1,\n",
    "                 'n_estimators': 500,\n",
    "                 'objective': 'mae',\n",
    "                 'learning_rate': 0.014912792408663157,\n",
    "                 'num_leaves': 21,\n",
    "                 'max_depth': 8,\n",
    "                 'max_bin': 140,\n",
    "                 'min_child_samples': 700,\n",
    "                 'min_split_gain': 0.1,\n",
    "                 'subsample': 0.9986785929006112,\n",
    "                 'subsample_freq': 1,\n",
    "                 'colsample_bytree': 0.974113126619188,\n",
    "                 'reg_alpha': 55,\n",
    "                 'reg_lambda': 42}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb379f",
   "metadata": {},
   "source": [
    "**Проверяем параметры на CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "568c6c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l1: 1.64693\n",
      "MAE fold 1 = 1.647\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[307]\tvalid_0's l1: 1.18681\n",
      "MAE fold 2 = 1.187\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's l1: 1.30105\n",
      "MAE fold 3 = 1.301\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l1: 1.50852\n",
      "MAE fold 4 = 1.509\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[496]\tvalid_0's l1: 1.74855\n",
      "MAE fold 5 = 1.749\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l1: 1.96094\n",
      "MAE fold 6 = 1.961\n",
      "---\n",
      "Mean MAE val = 1.5588003525948944\n",
      "Mean MAE train = 1.385722003015296\n",
      "Delta between train and val = 12.5 %\n"
     ]
    }
   ],
   "source": [
    "predicts_test, avg_mae_train = train_lgbm_cv(**lgbm_3_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39b11162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE holdout = 1.6383688674840295\n",
      "Delta between train and holdout = 18.2 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 2</td>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 3</td>\n",
       "      <td>1.638369</td>\n",
       "      <td>2.201705</td>\n",
       "      <td>0.503372</td>\n",
       "      <td>19.331786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901\n",
       "0                lgbm tune 2  1.632234  2.165808     0.519434  19.259403\n",
       "0                lgbm tune 3  1.638369  2.201705     0.503372  19.331786"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_preds = np.mean(np.column_stack(predicts_test), axis=1)\n",
    "mae_holdout = mean_absolute_error(y_test, holdout_preds)\n",
    "print(f\"MAE holdout = {mae_holdout}\")\n",
    "print(\n",
    "    f\"Delta between train and holdout = {(abs(avg_mae_train - mae_holdout) / avg_mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, holdout_preds, X_test, 'lgbm tune 3')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8223ff8",
   "metadata": {},
   "source": [
    "Третья комбинация гиперпараметров оказалась еще лучше для борьбы с переобучением, чем предыдущие две. Метрика на отложенной выборке еще немного ухудшилась, что может быть связано с увеличением смещения модели при снижении дисперсии, однако в данном случае переобучение снизилось значительно, а метрика на holdout ухудшилась незначительно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90935f",
   "metadata": {},
   "source": [
    "## LGBM Tune 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bd9c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_4_lgb(trial):\n",
    "    lgb_params = {\n",
    "        \"random_state\":\n",
    "        trial.suggest_categorical(\"random_state\", [42]),\n",
    "        \"verbose\":\n",
    "        trial.suggest_categorical(\"verbose\", [-1]),\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [500]),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_categorical(\"learning_rate\", [0.021936391093076747]),\n",
    "        #          \"objective\":\n",
    "        #         trial.suggest_categorical(\"objective\", ['mae', 'rmse', None]),\n",
    "        #         \"learning_rate\":\n",
    "        #         trial.suggest_float(\"learning_rate\", 0.009, 0.025, log=True),\n",
    "        \"num_leaves\":\n",
    "        trial.suggest_int(\"num_leaves\", 16, 30),\n",
    "        \"max_depth\":\n",
    "        trial.suggest_int(\"max_depth\", 6, 12),\n",
    "        \"max_bin\":\n",
    "        trial.suggest_int(\"max_bin\", 100, 250, step=10),\n",
    "        \"min_child_samples\":\n",
    "        trial.suggest_int(\"min_child_samples\", 100, 1000, step=100),\n",
    "        \"min_split_gain\":\n",
    "        trial.suggest_float(\"min_split_gain\", 0.0, 0.9, step=0.1),\n",
    "        \"subsample\":\n",
    "        trial.suggest_float(\"subsample\", 0.8, 1.0),\n",
    "        \"subsample_freq\":\n",
    "        trial.suggest_int(\"subsample_freq\", 1, 3),\n",
    "        \"colsample_bytree\":\n",
    "        trial.suggest_float(\"colsample_bytree\", 0.8, 1.0),\n",
    "        \"reg_alpha\":\n",
    "        trial.suggest_int(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\":\n",
    "        trial.suggest_int(\"reg_lambda\", 0, 100)\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'mae')\n",
    "\n",
    "    mae_oof = np.empty(6)\n",
    "    for idx, patient in enumerate(patients):\n",
    "        X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        X_val = train.loc[train.p_num == patient].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "        y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        model.fit(\n",
    "            X_train_,\n",
    "            y_train_,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric=\"mae\",\n",
    "            callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        mae_oof[idx] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    # последний фолд(1 + 6 пациенты)\n",
    "    X_train_ = train.loc[~((train.p_num == 'p06') | (train.p_num == 'p01'))].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    X_val = train.loc[(train.p_num == 'p06') | (\n",
    "        train.p_num == 'p01')].drop(['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))]['target']\n",
    "    y_val = train.loc[(train.p_num == 'p06') | (\n",
    "        train.p_num == 'p01')]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgb_params)\n",
    "    model.fit(\n",
    "        X_train_,\n",
    "        y_train_,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"mae\",\n",
    "        callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    mae_oof[idx + 1] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    return np.mean(mae_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a977a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_4_lgb = optuna.create_study(direction=\"minimize\", study_name=\"LGB_4\")\n",
    "study_4_lgb.optimize(objective_4_lgb, n_trials=15, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_4_lgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d74eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_4_lgb.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04e21048",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_4_params = {'random_state': 42,\n",
    "                 'verbose': -1,\n",
    "                 'n_estimators': 500,\n",
    "                 'learning_rate': 0.021936391093076747,\n",
    "                 'num_leaves': 23,\n",
    "                 'max_depth': 6,\n",
    "                 'max_bin': 140,\n",
    "                 'min_child_samples': 1000,\n",
    "                 'min_split_gain': 0.0,\n",
    "                 'subsample': 0.8809963922091697,\n",
    "                 'subsample_freq': 1,\n",
    "                 'colsample_bytree': 0.9906721118787845,\n",
    "                 'reg_alpha': 13,\n",
    "                 'reg_lambda': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd56297",
   "metadata": {},
   "source": [
    "**Проверяем параметры на CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93762636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's l1: 1.629\tvalid_0's l2: 5.10374\n",
      "MAE fold 1 = 1.629\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's l1: 1.28544\tvalid_0's l2: 2.60165\n",
      "MAE fold 2 = 1.285\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's l1: 1.32444\tvalid_0's l2: 3.23219\n",
      "MAE fold 3 = 1.324\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l1: 1.51122\tvalid_0's l2: 4.00424\n",
      "MAE fold 4 = 1.511\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l1: 1.7105\tvalid_0's l2: 5.12673\n",
      "MAE fold 5 = 1.711\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l1: 1.9517\tvalid_0's l2: 6.52526\n",
      "MAE fold 6 = 1.952\n",
      "---\n",
      "Mean MAE val = 1.5687179819764652\n",
      "Mean MAE train = 1.359012324198237\n",
      "Delta between train and val = 15.4 %\n"
     ]
    }
   ],
   "source": [
    "predicts_test, avg_mae_train = train_lgbm_cv(**lgbm_4_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9765506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE holdout = 1.6255045781048656\n",
      "Delta between train and holdout = 19.6 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 2</td>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 3</td>\n",
       "      <td>1.638369</td>\n",
       "      <td>2.201705</td>\n",
       "      <td>0.503372</td>\n",
       "      <td>19.331786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 4</td>\n",
       "      <td>1.625505</td>\n",
       "      <td>2.159397</td>\n",
       "      <td>0.522275</td>\n",
       "      <td>19.179995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901\n",
       "0                lgbm tune 2  1.632234  2.165808     0.519434  19.259403\n",
       "0                lgbm tune 3  1.638369  2.201705     0.503372  19.331786\n",
       "0                lgbm tune 4  1.625505  2.159397     0.522275  19.179995"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_preds = np.mean(np.column_stack(predicts_test), axis=1)\n",
    "mae_holdout = mean_absolute_error(y_test, holdout_preds)\n",
    "print(f\"MAE holdout = {mae_holdout}\")\n",
    "print(\n",
    "    f\"Delta between train and holdout = {(abs(avg_mae_train - mae_holdout) / avg_mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, holdout_preds, X_test, 'lgbm tune 4')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d95014",
   "metadata": {},
   "source": [
    "Данная комбинация гиперпараметров так же позволила снизить переобучение по сравнению с бейзлайном, но оказалась хуже, чем предыдущие."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51e459",
   "metadata": {},
   "source": [
    "## LGBM Tune 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_5_lgb(trial):\n",
    "    lgb_params = {\n",
    "        \"random_state\":\n",
    "        trial.suggest_categorical(\"random_state\", [42]),\n",
    "        \"verbose\":\n",
    "        trial.suggest_categorical(\"verbose\", [-1]),\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [1000]),\n",
    "        \"objective\":\n",
    "        trial.suggest_categorical(\"objective\", ['mae']),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_categorical(\"learning_rate\", [0.005483200175064182]),\n",
    "        #          \"objective\":\n",
    "        #         trial.suggest_categorical(\"objective\", ['mae', 'rmse', None]),\n",
    "        #         \"learning_rate\":\n",
    "        #         trial.suggest_float(\"learning_rate\", 0.005, 0.008, log=True)\n",
    "        \"num_leaves\":\n",
    "        trial.suggest_int(\"num_leaves\", 16, 22),\n",
    "        \"max_depth\":\n",
    "        trial.suggest_int(\"max_depth\", 6, 10),\n",
    "        \"max_bin\":\n",
    "        trial.suggest_int(\"max_bin\", 100, 250, step=10),\n",
    "        \"min_child_samples\":\n",
    "        trial.suggest_int(\"min_child_samples\", 100, 1000, step=100),\n",
    "        \"min_split_gain\":\n",
    "        trial.suggest_float(\"min_split_gain\", 0.0, 0.9, step=0.1),\n",
    "        \"subsample\":\n",
    "        trial.suggest_float(\"subsample\", 0.8, 1.0),\n",
    "        \"subsample_freq\":\n",
    "        trial.suggest_int(\"subsample_freq\", 1, 3),\n",
    "        \"colsample_bytree\":\n",
    "        trial.suggest_float(\"colsample_bytree\", 0.8, 1.0),\n",
    "        \"reg_alpha\":\n",
    "        trial.suggest_int(\"reg_alpha\", 0, 100),\n",
    "        \"reg_lambda\":\n",
    "        trial.suggest_int(\"reg_lambda\", 0, 100)\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'mae')\n",
    "\n",
    "    mae_oof = np.empty(6)\n",
    "    for idx, patient in enumerate(patients):\n",
    "        X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'],\n",
    "                                                       axis=1)\n",
    "        y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "        y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "        model = LGBMRegressor(**lgb_params)\n",
    "        model.fit(X_train_,\n",
    "                  y_train_,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric=\"mae\",\n",
    "                  callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        mae_oof[idx] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    # последний фолд(1 + 6 пациенты)\n",
    "    X_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))].drop(['p_num', 'target'],\n",
    "                                                         axis=1)\n",
    "    X_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))]['target']\n",
    "    y_val = train.loc[(train.p_num == 'p06') |\n",
    "                      (train.p_num == 'p01')]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgb_params)\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric=\"mae\",\n",
    "              callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    mae_oof[idx + 1] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    return np.mean(mae_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b18a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_5_lgb = optuna.create_study(direction=\"minimize\", study_name=\"LGB_5\")\n",
    "study_5_lgb.optimize(objective_5_lgb, n_trials=12, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_5_lgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_5_lgb.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86d9d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_5_params = {'random_state': 42,\n",
    " 'verbose': -1,\n",
    " 'n_estimators': 1000,\n",
    " 'objective': 'mae',\n",
    " 'learning_rate': 0.005483200175064182,\n",
    " 'num_leaves': 22,\n",
    " 'max_depth': 8,\n",
    " 'max_bin': 170,\n",
    " 'min_child_samples': 600,\n",
    " 'min_split_gain': 0.9,\n",
    " 'subsample': 0.8104803788268242,\n",
    " 'subsample_freq': 2,\n",
    " 'colsample_bytree': 0.9987695679080075,\n",
    " 'reg_alpha': 44,\n",
    " 'reg_lambda': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa7aec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's l1: 1.65133\n",
      "MAE fold 1 = 1.651\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[818]\tvalid_0's l1: 1.18961\n",
      "MAE fold 2 = 1.190\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[839]\tvalid_0's l1: 1.30086\n",
      "MAE fold 3 = 1.301\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 1.50924\n",
      "MAE fold 4 = 1.509\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 1.75208\n",
      "MAE fold 5 = 1.752\n",
      "---\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 1.97032\n",
      "MAE fold 6 = 1.970\n",
      "---\n",
      "Mean MAE val = 1.5622397270327497\n",
      "Mean MAE train = 1.395235387404081\n",
      "Delta between train and val = 12.0 %\n"
     ]
    }
   ],
   "source": [
    "predicts_test, avg_mae_train = train_lgbm_cv(**lgbm_5_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fff06b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE holdout = 1.6441050178052556\n",
      "Delta between train and holdout = 17.8 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 2</td>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 3</td>\n",
       "      <td>1.638369</td>\n",
       "      <td>2.201705</td>\n",
       "      <td>0.503372</td>\n",
       "      <td>19.331786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 4</td>\n",
       "      <td>1.625505</td>\n",
       "      <td>2.159397</td>\n",
       "      <td>0.522275</td>\n",
       "      <td>19.179995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 5</td>\n",
       "      <td>1.644105</td>\n",
       "      <td>2.206120</td>\n",
       "      <td>0.501378</td>\n",
       "      <td>19.399469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901\n",
       "0                lgbm tune 2  1.632234  2.165808     0.519434  19.259403\n",
       "0                lgbm tune 3  1.638369  2.201705     0.503372  19.331786\n",
       "0                lgbm tune 4  1.625505  2.159397     0.522275  19.179995\n",
       "0                lgbm tune 5  1.644105  2.206120     0.501378  19.399469"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_preds = np.mean(np.column_stack(predicts_test), axis=1)\n",
    "mae_holdout = mean_absolute_error(y_test, holdout_preds)\n",
    "print(f\"MAE holdout = {mae_holdout}\")\n",
    "print(\n",
    "    f\"Delta between train and holdout = {(abs(avg_mae_train - mae_holdout) / avg_mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, holdout_preds, X_test, 'lgbm tune 5')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c6258",
   "metadata": {},
   "source": [
    "Данная комбинация гиперпараметров оказалась лучше всех предыдущих, так как способствовала наибольшему снижению переобучения. Метрика на отложенной выборке хуже, но незначительно, прирост устойчивости модели к переобучению гораздо больше и значительнее, а также важнее в рамках задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb78883",
   "metadata": {},
   "source": [
    "# Tuning CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bbb9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cb(trial):\n",
    "    cb_params = {\n",
    "        \"iterations\":\n",
    "        trial.suggest_categorical(\"iterations\", [1000]),\n",
    "        \"random_state\":\n",
    "        trial.suggest_categorical(\"random_state\", [42]),\n",
    "        \"eval_metric\":\n",
    "        trial.suggest_categorical(\"eval_metric\", ['MAE']),\n",
    "        \"loss_function\":\n",
    "        trial.suggest_categorical(\"loss_function\", ['MAE']),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_categorical(\"learning_rate\", [0.029999999329447743]),\n",
    "        #         \"loss_function\":\n",
    "        #         trial.suggest_categorical(\"loss_function\", ['MAE', 'RMSE']),\n",
    "        #         \"learning_rate\":\n",
    "        #         trial.suggest_float(\"learning_rate\", 0.025, 0.035, log=True)\n",
    "        \"l2_leaf_reg\":\n",
    "        trial.suggest_int(\"l2_leaf_reg\", 3, 5, step=2),\n",
    "        \"border_count\":\n",
    "        trial.suggest_int(\"border_count\", 230, 250, step=10)\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'mae')\n",
    "\n",
    "    mae_oof = np.empty(6)\n",
    "    for idx, patient in enumerate(patients):\n",
    "        X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "            ['p_num', 'target'], axis=1)\n",
    "        X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'],\n",
    "                                                       axis=1)\n",
    "        y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "        y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "        model = CatBoostRegressor(**cb_params)\n",
    "\n",
    "        eval_set = [(X_val, y_val)]\n",
    "\n",
    "        model.fit(X_train_,\n",
    "                  y_train_,\n",
    "                  eval_set=eval_set,\n",
    "                  verbose=False,\n",
    "                  early_stopping_rounds=100)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        mae_oof[idx] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    # последний фолд(1 + 6 пациенты)\n",
    "    X_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))].drop(['p_num', 'target'],\n",
    "                                                         axis=1)\n",
    "    X_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                           (train.p_num == 'p01'))]['target']\n",
    "    y_val = train.loc[(train.p_num == 'p06') |\n",
    "                      (train.p_num == 'p01')]['target']\n",
    "\n",
    "    model = CatBoostRegressor(**cb_params)\n",
    "\n",
    "    eval_set = [(X_val, y_val)]\n",
    "\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=eval_set,\n",
    "              verbose=False,\n",
    "              early_stopping_rounds=100)\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    mae_oof[idx + 1] = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    return np.mean(mae_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ad671",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_cb = optuna.create_study(direction=\"minimize\", study_name=\"CatBoost\")\n",
    "study_cb.optimize(objective_cb, n_trials=5, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_cb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_cb.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd5c284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {'iterations': 1000,\n",
    " 'random_state': 42,\n",
    " 'eval_metric': 'MAE',\n",
    " 'loss_function': 'MAE',\n",
    " 'learning_rate': 0.029999999329447743,\n",
    " 'l2_leaf_reg': 5,\n",
    " 'border_count': 240}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f52fe549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE fold 1 = 1.711\n",
      "---\n",
      "MAE fold 2 = 1.156\n",
      "---\n",
      "MAE fold 3 = 1.312\n",
      "---\n",
      "MAE fold 4 = 1.512\n",
      "---\n",
      "MAE fold 5 = 1.744\n",
      "---\n",
      "MAE fold 6 = 1.951\n",
      "---\n",
      "Mean MAE val = 1.5641584170670286\n",
      "Mean MAE train = 1.3929251340837556\n",
      "Delta between train and val = 12.3 %\n"
     ]
    }
   ],
   "source": [
    "predicts_test, avg_mae_train = train_catboost_cv(**catboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "048d2bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE holdout = 1.6637519839226906\n",
      "Delta between train and holdout = 19.4 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 2</td>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 3</td>\n",
       "      <td>1.638369</td>\n",
       "      <td>2.201705</td>\n",
       "      <td>0.503372</td>\n",
       "      <td>19.331786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 4</td>\n",
       "      <td>1.625505</td>\n",
       "      <td>2.159397</td>\n",
       "      <td>0.522275</td>\n",
       "      <td>19.179995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 5</td>\n",
       "      <td>1.644105</td>\n",
       "      <td>2.206120</td>\n",
       "      <td>0.501378</td>\n",
       "      <td>19.399469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost tune</td>\n",
       "      <td>1.663752</td>\n",
       "      <td>2.227744</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>19.631292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901\n",
       "0                lgbm tune 2  1.632234  2.165808     0.519434  19.259403\n",
       "0                lgbm tune 3  1.638369  2.201705     0.503372  19.331786\n",
       "0                lgbm tune 4  1.625505  2.159397     0.522275  19.179995\n",
       "0                lgbm tune 5  1.644105  2.206120     0.501378  19.399469\n",
       "0              catboost tune  1.663752  2.227744     0.491556  19.631292"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_preds = np.mean(np.column_stack(predicts_test), axis=1)\n",
    "mae_holdout = mean_absolute_error(y_test, holdout_preds)\n",
    "print(f\"MAE holdout = {mae_holdout}\")\n",
    "print(\n",
    "    f\"Delta between train and holdout = {(abs(avg_mae_train - mae_holdout) / avg_mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, holdout_preds, X_test, 'catboost tune')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ad8f2",
   "metadata": {},
   "source": [
    "Тюнинг Catboost способствовал очень значительному снижению переобучения: у baseline Catboost с кросс-валидацией разница между метриками на трейне и тесте была 27.9%, а стала 19.4%; разница между метриками на трейне и кросс-валидации была 22.3%, а стала 12.3%. По проценту переобучения на кросс-валидации Catboost с подобранными гиперпараметрами - одна из лучших моделей наряду с lightGBM с 3-й и 5-й комбинациями гиперпараметров.Однако метрика на отложенной выборке у Catboost хуже, чем у LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece31600",
   "metadata": {},
   "source": [
    "**Вывод по качеству моделей после тюнинга:** лучшие модели, наиболее устойчивые к переобучению - это LightGBM с 3-й и 5-й комбинациями гиперпараметров: у них самый низкий процент переобучения на валидационных и тестовых данных и очень незначительное ухудшение метрик на отложенной выборке, которое, вероятно, связано с bias-variance trade-off. Сatboost с подобранными гиперпараметрами почти так же хорош в плане переобучения, но метрика на holdout немного хуже, чем у LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901861e",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e3887b",
   "metadata": {},
   "source": [
    "## Stacking 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c6ccfa",
   "metadata": {},
   "source": [
    "Попробуем сделать стэкинг над тремя лучшими моделями - это LightGBM c параметрами lgbm_3_params, LightGBM c параметрами lgbm_5_params и Catboost(у Catboost результаты немного хуже, чем у первых двух моделей, но лучше добавить его в стэкинг для повышения разнородности базовых моделей)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff591cac",
   "metadata": {},
   "source": [
    "LightGBM lgbm_3_params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a14e0d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l1: 1.64693\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[307]\tvalid_0's l1: 1.18681\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's l1: 1.30105\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l1: 1.50852\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[496]\tvalid_0's l1: 1.74855\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l1: 1.96094\n"
     ]
    }
   ],
   "source": [
    "# создаем датафреймы с мета-признаками для трейна и теста\n",
    "meta_X = pd.DataFrame()\n",
    "meta_X_test = pd.DataFrame()\n",
    "\n",
    "predicts_val = []\n",
    "# первые пять фолдов\n",
    "for idx, patient in enumerate(patients):\n",
    "    X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "    y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgbm_3_params)\n",
    "    model.fit(\n",
    "        X_train_,\n",
    "        y_train_,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"mae\",\n",
    "        callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    predicts_val.append(y_val_pred)\n",
    "\n",
    "# последний фолд(1 + 6 пациенты)\n",
    "X_train_ = train.loc[~((train.p_num == 'p06') | (train.p_num == 'p01'))].drop(\n",
    "    ['p_num', 'target'], axis=1)\n",
    "X_val = train.loc[(train.p_num == 'p06') | (\n",
    "    train.p_num == 'p01')].drop(['p_num', 'target'], axis=1)\n",
    "y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                       (train.p_num == 'p01'))]['target']\n",
    "y_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')]['target']\n",
    "\n",
    "model = LGBMRegressor(**lgbm_3_params)\n",
    "model.fit(\n",
    "    X_train_,\n",
    "    y_train_,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"mae\",\n",
    "    callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "predicts_val.append(y_val_pred)\n",
    "\n",
    "# обучаем модель на полной тренировочной выборке для получения предсказаний (мета-признаков) на тесте\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# добавляем первый мета-признак в датафреймы с мета-признаками для трейна и теста\n",
    "meta_X['lgbm_1'] = np.concatenate(predicts_val)\n",
    "meta_X_test['lgbm_1'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975d549",
   "metadata": {},
   "source": [
    "Добавляем в стэкинг LightGBM с lgbm_5_params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f8e2c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's l1: 1.65133\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[818]\tvalid_0's l1: 1.18961\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[839]\tvalid_0's l1: 1.30086\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 1.50924\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 1.75208\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's l1: 1.97032\n"
     ]
    }
   ],
   "source": [
    "predicts_val = []\n",
    "# первые пять фолдов\n",
    "for idx, patient in enumerate(patients):\n",
    "    X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "    y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgbm_5_params)\n",
    "    model.fit(\n",
    "        X_train_,\n",
    "        y_train_,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"mae\",\n",
    "        callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    predicts_val.append(y_val_pred)\n",
    "\n",
    "# последний фолд(1 + 6 пациенты)\n",
    "X_train_ = train.loc[~((train.p_num == 'p06') | (train.p_num == 'p01'))].drop(\n",
    "    ['p_num', 'target'], axis=1)\n",
    "X_val = train.loc[(train.p_num == 'p06') | (\n",
    "    train.p_num == 'p01')].drop(['p_num', 'target'], axis=1)\n",
    "y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                       (train.p_num == 'p01'))]['target']\n",
    "y_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')]['target']\n",
    "\n",
    "model = LGBMRegressor(**lgbm_5_params)\n",
    "model.fit(\n",
    "    X_train_,\n",
    "    y_train_,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"mae\",\n",
    "    callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "predicts_val.append(y_val_pred)\n",
    "\n",
    "# обучаем модель на полной тренировочной выборке для получения предсказаний (мета-признаков) на тесте\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# добавляем первый мета-признак в датафреймы с мета-признаками для трейна и теста\n",
    "meta_X['lgbm_2'] = np.concatenate(predicts_val)\n",
    "meta_X_test['lgbm_2'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee8e6d",
   "metadata": {},
   "source": [
    "Добавляем Catboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "239156a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_val = []\n",
    "# первые пять фолдов\n",
    "for idx, patient in enumerate(patients):\n",
    "    X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "    y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "    model = CatBoostRegressor(**catboost_params)\n",
    "\n",
    "    eval_set = [(X_val, y_val)]\n",
    "\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=eval_set,\n",
    "              verbose=False,\n",
    "              early_stopping_rounds=100)\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    predicts_val.append(y_val_pred)\n",
    "\n",
    "# последний фолд(1 + 6 пациенты)\n",
    "X_train_ = train.loc[~((train.p_num == 'p06') | (train.p_num == 'p01'))].drop(\n",
    "    ['p_num', 'target'], axis=1)\n",
    "X_val = train.loc[(train.p_num == 'p06') | (\n",
    "    train.p_num == 'p01')].drop(['p_num', 'target'], axis=1)\n",
    "y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                       (train.p_num == 'p01'))]['target']\n",
    "y_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')]['target']\n",
    "\n",
    "model = CatBoostRegressor(**catboost_params)\n",
    "\n",
    "eval_set = [(X_val, y_val)]\n",
    "\n",
    "model.fit(X_train_,\n",
    "          y_train_,\n",
    "          eval_set=eval_set,\n",
    "          verbose=False,\n",
    "          early_stopping_rounds=100)\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "predicts_val.append(y_val_pred)\n",
    "\n",
    "# обучаем модель на полной тренировочной выборке для получения предсказаний (мета-признаков) на тесте\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# добавляем первый мета-признак в датафреймы с мета-признаками для трейна и теста\n",
    "meta_X['catboost'] = np.concatenate(predicts_val)\n",
    "meta_X_test['catboost'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c19b8",
   "metadata": {},
   "source": [
    "**Финальная мета-модель:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b019e421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train = 1.5284184280620579\n",
      "MAE test = 1.6036795141893496\n",
      "Delta = 4.9 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 2</td>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 3</td>\n",
       "      <td>1.638369</td>\n",
       "      <td>2.201705</td>\n",
       "      <td>0.503372</td>\n",
       "      <td>19.331786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 4</td>\n",
       "      <td>1.625505</td>\n",
       "      <td>2.159397</td>\n",
       "      <td>0.522275</td>\n",
       "      <td>19.179995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 5</td>\n",
       "      <td>1.644105</td>\n",
       "      <td>2.206120</td>\n",
       "      <td>0.501378</td>\n",
       "      <td>19.399469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost tune</td>\n",
       "      <td>1.663752</td>\n",
       "      <td>2.227744</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>19.631292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 3 models</td>\n",
       "      <td>1.603680</td>\n",
       "      <td>2.155724</td>\n",
       "      <td>0.523899</td>\n",
       "      <td>18.922472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901\n",
       "0                lgbm tune 2  1.632234  2.165808     0.519434  19.259403\n",
       "0                lgbm tune 3  1.638369  2.201705     0.503372  19.331786\n",
       "0                lgbm tune 4  1.625505  2.159397     0.522275  19.179995\n",
       "0                lgbm tune 5  1.644105  2.206120     0.501378  19.399469\n",
       "0              catboost tune  1.663752  2.227744     0.491556  19.631292\n",
       "0          stacking 3 models  1.603680  2.155724     0.523899  18.922472"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# в качестве финальной мета-модели используем простую линейную регрессию:\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(meta_X, y_train)\n",
    "\n",
    "y_pred_train = meta_model.predict(meta_X)\n",
    "y_pred_test = meta_model.predict(meta_X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MAE train = {mae_train}\")\n",
    "print(f\"MAE test = {mae_test}\")\n",
    "print(f\"Delta = {(abs(mae_train - mae_test) / mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, y_pred_test, X_test, 'stacking 3 models')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57495b69",
   "metadata": {},
   "source": [
    "Стэкинг трех лучших моделей позволил очень сильно снизить переобучение, а также улучшить метрику на отложенной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff0d2b",
   "metadata": {},
   "source": [
    "## Stacking 4 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27fb84a",
   "metadata": {},
   "source": [
    "Попробуем добавить в стэкинг еще 4 модель (с lgbm_2_params):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e722efa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[94]\tvalid_0's l1: 1.63002\tvalid_0's l2: 5.10138\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 1.29186\tvalid_0's l2: 2.63065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[81]\tvalid_0's l1: 1.31681\tvalid_0's l2: 3.19354\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's l1: 1.543\tvalid_0's l2: 4.1296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's l1: 1.70939\tvalid_0's l2: 5.11418\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's l1: 1.96795\tvalid_0's l2: 6.59215\n"
     ]
    }
   ],
   "source": [
    "predicts_val = []\n",
    "# первые пять фолдов\n",
    "for idx, patient in enumerate(patients):\n",
    "    X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "    y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgbm_2_params)\n",
    "    model.fit(\n",
    "        X_train_,\n",
    "        y_train_,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"mae\",\n",
    "        callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    predicts_val.append(y_val_pred)\n",
    "\n",
    "# последний фолд(1 + 6 пациенты)\n",
    "X_train_ = train.loc[~((train.p_num == 'p06') | (train.p_num == 'p01'))].drop(\n",
    "    ['p_num', 'target'], axis=1)\n",
    "X_val = train.loc[(train.p_num == 'p06') | (\n",
    "    train.p_num == 'p01')].drop(['p_num', 'target'], axis=1)\n",
    "y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                       (train.p_num == 'p01'))]['target']\n",
    "y_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')]['target']\n",
    "\n",
    "model = LGBMRegressor(**lgbm_2_params)\n",
    "model.fit(\n",
    "    X_train_,\n",
    "    y_train_,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"mae\",\n",
    "    callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "predicts_val.append(y_val_pred)\n",
    "\n",
    "# обучаем модель на полной тренировочной выборке для получения предсказаний (мета-признаков) на тесте\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# добавляем первый мета-признак в датафреймы с мета-признаками для трейна и теста\n",
    "meta_X['lgbm_3'] = np.concatenate(predicts_val)\n",
    "meta_X_test['lgbm_3'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb03e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train = 1.526122957506064\n",
      "MAE test = 1.6031152346539208\n",
      "Delta = 5.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 2</td>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 3</td>\n",
       "      <td>1.638369</td>\n",
       "      <td>2.201705</td>\n",
       "      <td>0.503372</td>\n",
       "      <td>19.331786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 4</td>\n",
       "      <td>1.625505</td>\n",
       "      <td>2.159397</td>\n",
       "      <td>0.522275</td>\n",
       "      <td>19.179995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 5</td>\n",
       "      <td>1.644105</td>\n",
       "      <td>2.206120</td>\n",
       "      <td>0.501378</td>\n",
       "      <td>19.399469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost tune</td>\n",
       "      <td>1.663752</td>\n",
       "      <td>2.227744</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>19.631292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 3 models</td>\n",
       "      <td>1.603680</td>\n",
       "      <td>2.155724</td>\n",
       "      <td>0.523899</td>\n",
       "      <td>18.922472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 4 models</td>\n",
       "      <td>1.603115</td>\n",
       "      <td>2.150508</td>\n",
       "      <td>0.526200</td>\n",
       "      <td>18.915814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901\n",
       "0                lgbm tune 2  1.632234  2.165808     0.519434  19.259403\n",
       "0                lgbm tune 3  1.638369  2.201705     0.503372  19.331786\n",
       "0                lgbm tune 4  1.625505  2.159397     0.522275  19.179995\n",
       "0                lgbm tune 5  1.644105  2.206120     0.501378  19.399469\n",
       "0              catboost tune  1.663752  2.227744     0.491556  19.631292\n",
       "0          stacking 3 models  1.603680  2.155724     0.523899  18.922472\n",
       "0          stacking 4 models  1.603115  2.150508     0.526200  18.915814"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model = LinearRegression()\n",
    "meta_model.fit(meta_X, y_train)\n",
    "\n",
    "y_pred_train = meta_model.predict(meta_X)\n",
    "y_pred_test = meta_model.predict(meta_X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MAE train = {mae_train}\")\n",
    "print(f\"MAE test = {mae_test}\")\n",
    "print(f\"Delta = {(abs(mae_train - mae_test) / mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, y_pred_test, X_test, 'stacking 4 models')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20affd8b",
   "metadata": {},
   "source": [
    "Добавление 4 модели не повлияло на переобучение, но совсем немного улучшило метрику на отложенной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5183c355",
   "metadata": {},
   "source": [
    "## Stacking 5 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e168790",
   "metadata": {},
   "source": [
    "Попробуем добавить в стэкинг 5-ю модель (с lgbm_1_params):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc40fc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 1.65099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[81]\tvalid_0's l1: 1.18964\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\tvalid_0's l1: 1.29595\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 1.49862\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's l1: 1.75268\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 1.98058\n"
     ]
    }
   ],
   "source": [
    "predicts_val = []\n",
    "# первые пять фолдов\n",
    "for idx, patient in enumerate(patients):\n",
    "    X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "    y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgbm_1_params)\n",
    "    model.fit(\n",
    "        X_train_,\n",
    "        y_train_,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"mae\",\n",
    "        callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    predicts_val.append(y_val_pred)\n",
    "\n",
    "# последний фолд(1 + 6 пациенты)\n",
    "X_train_ = train.loc[~((train.p_num == 'p06') | (train.p_num == 'p01'))].drop(\n",
    "    ['p_num', 'target'], axis=1)\n",
    "X_val = train.loc[(train.p_num == 'p06') | (\n",
    "    train.p_num == 'p01')].drop(['p_num', 'target'], axis=1)\n",
    "y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                       (train.p_num == 'p01'))]['target']\n",
    "y_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')]['target']\n",
    "\n",
    "model = LGBMRegressor(**lgbm_1_params)\n",
    "model.fit(\n",
    "    X_train_,\n",
    "    y_train_,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"mae\",\n",
    "    callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "predicts_val.append(y_val_pred)\n",
    "\n",
    "# обучаем модель на полной тренировочной выборке для получения предсказаний (мета-признаков) на тесте\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# добавляем первый мета-признак в датафреймы с мета-признаками для трейна и теста\n",
    "meta_X['lgbm_4'] = np.concatenate(predicts_val)\n",
    "meta_X_test['lgbm_4'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bc0f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train = 1.5262357635842605\n",
      "MAE test = 1.6027954248888743\n",
      "Delta = 5.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 2</td>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 3</td>\n",
       "      <td>1.638369</td>\n",
       "      <td>2.201705</td>\n",
       "      <td>0.503372</td>\n",
       "      <td>19.331786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 4</td>\n",
       "      <td>1.625505</td>\n",
       "      <td>2.159397</td>\n",
       "      <td>0.522275</td>\n",
       "      <td>19.179995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 5</td>\n",
       "      <td>1.644105</td>\n",
       "      <td>2.206120</td>\n",
       "      <td>0.501378</td>\n",
       "      <td>19.399469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost tune</td>\n",
       "      <td>1.663752</td>\n",
       "      <td>2.227744</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>19.631292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 3 models</td>\n",
       "      <td>1.603680</td>\n",
       "      <td>2.155724</td>\n",
       "      <td>0.523899</td>\n",
       "      <td>18.922472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 4 models</td>\n",
       "      <td>1.603115</td>\n",
       "      <td>2.150508</td>\n",
       "      <td>0.526200</td>\n",
       "      <td>18.915814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 5 models</td>\n",
       "      <td>1.602795</td>\n",
       "      <td>2.150195</td>\n",
       "      <td>0.526338</td>\n",
       "      <td>18.912040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901\n",
       "0                lgbm tune 2  1.632234  2.165808     0.519434  19.259403\n",
       "0                lgbm tune 3  1.638369  2.201705     0.503372  19.331786\n",
       "0                lgbm tune 4  1.625505  2.159397     0.522275  19.179995\n",
       "0                lgbm tune 5  1.644105  2.206120     0.501378  19.399469\n",
       "0              catboost tune  1.663752  2.227744     0.491556  19.631292\n",
       "0          stacking 3 models  1.603680  2.155724     0.523899  18.922472\n",
       "0          stacking 4 models  1.603115  2.150508     0.526200  18.915814\n",
       "0          stacking 5 models  1.602795  2.150195     0.526338  18.912040"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model = LinearRegression()\n",
    "meta_model.fit(meta_X, y_train)\n",
    "\n",
    "y_pred_train = meta_model.predict(meta_X)\n",
    "y_pred_test = meta_model.predict(meta_X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MAE train = {mae_train}\")\n",
    "print(f\"MAE test = {mae_test}\")\n",
    "print(f\"Delta = {(abs(mae_train - mae_test) / mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, y_pred_test, X_test, 'stacking 5 models')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3fec6",
   "metadata": {},
   "source": [
    "Добавление 5-й модели еще немного улучшило метрику на отложенной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef0bd0",
   "metadata": {},
   "source": [
    "## Stacking 6 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe80a999",
   "metadata": {},
   "source": [
    "Попробуем добавить в стэкинг 6-ю модель (с lgbm_4_params):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6b69eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's l1: 1.629\tvalid_0's l2: 5.10374\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's l1: 1.28544\tvalid_0's l2: 2.60165\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's l1: 1.32444\tvalid_0's l2: 3.23219\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l1: 1.51122\tvalid_0's l2: 4.00424\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\tvalid_0's l1: 1.7105\tvalid_0's l2: 5.12673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's l1: 1.9517\tvalid_0's l2: 6.52526\n"
     ]
    }
   ],
   "source": [
    "predicts_val = []\n",
    "# первые пять фолдов\n",
    "for idx, patient in enumerate(patients):\n",
    "    X_train_ = train.loc[~(train.p_num == patient)].drop(\n",
    "        ['p_num', 'target'], axis=1)\n",
    "    X_val = train.loc[train.p_num == patient].drop(['p_num', 'target'], axis=1)\n",
    "    y_train_ = train.loc[~(train.p_num == patient)]['target']\n",
    "    y_val = train.loc[train.p_num == patient]['target']\n",
    "\n",
    "    model = LGBMRegressor(**lgbm_4_params)\n",
    "    model.fit(\n",
    "        X_train_,\n",
    "        y_train_,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=\"mae\",\n",
    "        callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    predicts_val.append(y_val_pred)\n",
    "\n",
    "# последний фолд(1 + 6 пациенты)\n",
    "X_train_ = train.loc[~((train.p_num == 'p06') | (train.p_num == 'p01'))].drop(\n",
    "    ['p_num', 'target'], axis=1)\n",
    "X_val = train.loc[(train.p_num == 'p06') | (\n",
    "    train.p_num == 'p01')].drop(['p_num', 'target'], axis=1)\n",
    "y_train_ = train.loc[~((train.p_num == 'p06') |\n",
    "                       (train.p_num == 'p01'))]['target']\n",
    "y_val = train.loc[(train.p_num == 'p06') | (train.p_num == 'p01')]['target']\n",
    "\n",
    "model = LGBMRegressor(**lgbm_4_params)\n",
    "model.fit(\n",
    "    X_train_,\n",
    "    y_train_,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"mae\",\n",
    "    callbacks=[early_stopping(stopping_rounds=100)])\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "predicts_val.append(y_val_pred)\n",
    "\n",
    "# обучаем модель на полной тренировочной выборке для получения предсказаний (мета-признаков) на тесте\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# добавляем первый мета-признак в датафреймы с мета-признаками для трейна и теста\n",
    "meta_X['lgbm_5'] = np.concatenate(predicts_val)\n",
    "meta_X_test['lgbm_5'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7897abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train = 1.5241357588111524\n",
      "MAE test = 1.594744789173618\n",
      "Delta = 4.6 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline lasso</td>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline ridge</td>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline lgbm</td>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline catboost</td>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline ridge with CV</td>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>baseline lgbm with CV</td>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline catboost with CV</td>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 1</td>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 2</td>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 3</td>\n",
       "      <td>1.638369</td>\n",
       "      <td>2.201705</td>\n",
       "      <td>0.503372</td>\n",
       "      <td>19.331786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 4</td>\n",
       "      <td>1.625505</td>\n",
       "      <td>2.159397</td>\n",
       "      <td>0.522275</td>\n",
       "      <td>19.179995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgbm tune 5</td>\n",
       "      <td>1.644105</td>\n",
       "      <td>2.206120</td>\n",
       "      <td>0.501378</td>\n",
       "      <td>19.399469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catboost tune</td>\n",
       "      <td>1.663752</td>\n",
       "      <td>2.227744</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>19.631292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 3 models</td>\n",
       "      <td>1.603680</td>\n",
       "      <td>2.155724</td>\n",
       "      <td>0.523899</td>\n",
       "      <td>18.922472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 4 models</td>\n",
       "      <td>1.603115</td>\n",
       "      <td>2.150508</td>\n",
       "      <td>0.526200</td>\n",
       "      <td>18.915814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 5 models</td>\n",
       "      <td>1.602795</td>\n",
       "      <td>2.150195</td>\n",
       "      <td>0.526338</td>\n",
       "      <td>18.912040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stacking 6 models</td>\n",
       "      <td>1.594745</td>\n",
       "      <td>2.142871</td>\n",
       "      <td>0.529559</td>\n",
       "      <td>18.817048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       MAE      RMSE  R2 adjusted     WAPE_%\n",
       "0             baseline lasso  1.759607  2.310597     0.453032  20.762326\n",
       "1             baseline ridge  1.644019  2.196696     0.505629  19.398459\n",
       "2              baseline lgbm  1.623072  2.162940     0.520706  19.151295\n",
       "3          baseline catboost  1.645628  2.206858     0.501044  19.417439\n",
       "4     baseline ridge with CV  1.649097  2.223375     0.493548  19.458377\n",
       "5      baseline lgbm with CV  1.629086  2.161262     0.521449  19.222255\n",
       "6  baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "0                lgbm tune 1  1.629734  2.192108     0.507692  19.229901\n",
       "0                lgbm tune 2  1.632234  2.165808     0.519434  19.259403\n",
       "0                lgbm tune 3  1.638369  2.201705     0.503372  19.331786\n",
       "0                lgbm tune 4  1.625505  2.159397     0.522275  19.179995\n",
       "0                lgbm tune 5  1.644105  2.206120     0.501378  19.399469\n",
       "0              catboost tune  1.663752  2.227744     0.491556  19.631292\n",
       "0          stacking 3 models  1.603680  2.155724     0.523899  18.922472\n",
       "0          stacking 4 models  1.603115  2.150508     0.526200  18.915814\n",
       "0          stacking 5 models  1.602795  2.150195     0.526338  18.912040\n",
       "0          stacking 6 models  1.594745  2.142871     0.529559  18.817048"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model = LinearRegression()\n",
    "meta_model.fit(meta_X, y_train)\n",
    "\n",
    "y_pred_train = meta_model.predict(meta_X)\n",
    "y_pred_test = meta_model.predict(meta_X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"MAE train = {mae_train}\")\n",
    "print(f\"MAE test = {mae_test}\")\n",
    "print(f\"Delta = {(abs(mae_train - mae_test) / mae_train * 100):.1f} %\")\n",
    "\n",
    "metrics = pd.concat([\n",
    "    metrics,\n",
    "    get_metrics_regression(y_test, y_pred_test, X_test, 'stacking 6 models')\n",
    "])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e8155",
   "metadata": {},
   "source": [
    "Добавление 6 модели в ансамбль способствовало небольшому дополнительному снижению переобучения и улчушению метрики на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00c1f490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 adjusted</th>\n",
       "      <th>WAPE_%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline lasso</th>\n",
       "      <td>1.759607</td>\n",
       "      <td>2.310597</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>20.762326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline ridge</th>\n",
       "      <td>1.644019</td>\n",
       "      <td>2.196696</td>\n",
       "      <td>0.505629</td>\n",
       "      <td>19.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline lgbm</th>\n",
       "      <td>1.623072</td>\n",
       "      <td>2.162940</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>19.151295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline catboost</th>\n",
       "      <td>1.645628</td>\n",
       "      <td>2.206858</td>\n",
       "      <td>0.501044</td>\n",
       "      <td>19.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline ridge with CV</th>\n",
       "      <td>1.649097</td>\n",
       "      <td>2.223375</td>\n",
       "      <td>0.493548</td>\n",
       "      <td>19.458377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline lgbm with CV</th>\n",
       "      <td>1.629086</td>\n",
       "      <td>2.161262</td>\n",
       "      <td>0.521449</td>\n",
       "      <td>19.222255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline catboost with CV</th>\n",
       "      <td>1.647048</td>\n",
       "      <td>2.186179</td>\n",
       "      <td>0.510351</td>\n",
       "      <td>19.434197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm tune 1</th>\n",
       "      <td>1.629734</td>\n",
       "      <td>2.192108</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>19.229901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm tune 2</th>\n",
       "      <td>1.632234</td>\n",
       "      <td>2.165808</td>\n",
       "      <td>0.519434</td>\n",
       "      <td>19.259403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm tune 3</th>\n",
       "      <td>1.638369</td>\n",
       "      <td>2.201705</td>\n",
       "      <td>0.503372</td>\n",
       "      <td>19.331786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm tune 4</th>\n",
       "      <td>1.625505</td>\n",
       "      <td>2.159397</td>\n",
       "      <td>0.522275</td>\n",
       "      <td>19.179995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm tune 5</th>\n",
       "      <td>1.644105</td>\n",
       "      <td>2.206120</td>\n",
       "      <td>0.501378</td>\n",
       "      <td>19.399469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost tune</th>\n",
       "      <td>1.663752</td>\n",
       "      <td>2.227744</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>19.631292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacking 3 models</th>\n",
       "      <td>1.603680</td>\n",
       "      <td>2.155724</td>\n",
       "      <td>0.523899</td>\n",
       "      <td>18.922472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacking 4 models</th>\n",
       "      <td>1.603115</td>\n",
       "      <td>2.150508</td>\n",
       "      <td>0.526200</td>\n",
       "      <td>18.915814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacking 5 models</th>\n",
       "      <td>1.602795</td>\n",
       "      <td>2.150195</td>\n",
       "      <td>0.526338</td>\n",
       "      <td>18.912040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stacking 6 models</th>\n",
       "      <td>1.594745</td>\n",
       "      <td>2.142871</td>\n",
       "      <td>0.529559</td>\n",
       "      <td>18.817048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                MAE      RMSE  R2 adjusted     WAPE_%\n",
       "model                                                                \n",
       "baseline lasso             1.759607  2.310597     0.453032  20.762326\n",
       "baseline ridge             1.644019  2.196696     0.505629  19.398459\n",
       "baseline lgbm              1.623072  2.162940     0.520706  19.151295\n",
       "baseline catboost          1.645628  2.206858     0.501044  19.417439\n",
       "baseline ridge with CV     1.649097  2.223375     0.493548  19.458377\n",
       "baseline lgbm with CV      1.629086  2.161262     0.521449  19.222255\n",
       "baseline catboost with CV  1.647048  2.186179     0.510351  19.434197\n",
       "lgbm tune 1                1.629734  2.192108     0.507692  19.229901\n",
       "lgbm tune 2                1.632234  2.165808     0.519434  19.259403\n",
       "lgbm tune 3                1.638369  2.201705     0.503372  19.331786\n",
       "lgbm tune 4                1.625505  2.159397     0.522275  19.179995\n",
       "lgbm tune 5                1.644105  2.206120     0.501378  19.399469\n",
       "catboost tune              1.663752  2.227744     0.491556  19.631292\n",
       "stacking 3 models          1.603680  2.155724     0.523899  18.922472\n",
       "stacking 4 models          1.603115  2.150508     0.526200  18.915814\n",
       "stacking 5 models          1.602795  2.150195     0.526338  18.912040\n",
       "stacking 6 models          1.594745  2.142871     0.529559  18.817048"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = metrics.set_index('model')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59db6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv(\"metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5e12b",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c51c416",
   "metadata": {},
   "source": [
    "- Лучшая модель после подбора гиперпараметров - это LightGBM с 5-й комбинацией гиперпараметров(lgbm_5_params). Эта модель переобучается значительно меньше, чем бейзлайн, то есть с помощью подбора гиперпараметров удалось улучшить обобщающую способность модели. Метрика на отложенной выборке немного ухудшилась, что, вероятно, обусловлено увеличением смещения модели при снижении ее дисперсии, однако это ухудшение незначительное. \n",
    "- Стэкинг 6 моделей (5 LGBM с различными гиперпараметрами и 1 Catboost c подобранными гиперпараметрами) способствовал еще большему снижению переобучения. Также с помощью стэкинга удалось добиться наилучшего значения метрики на отложенной выборке. \n",
    "- Поставленную цель - построить модель, обучающуюся на данных одних пациентов и выдающую релевантные предсказания на данных новых пациентов - можно считать выполненной. Однако при снижении дисперсии модели сильно пострадало ее смещение, о чем говорит ухудшение метрик на тренировочной выборке. \n",
    "- Модель можно улучшить сбором большего объема данных(от большего числа пациентов), а также улучшением качества самих данных(в использованных данных было очень много пропущеннных значений, некоторые признаки пришлось удалить из-за огромного количества пропусков)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.806px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
